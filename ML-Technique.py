# -*- coding: utf-8 -*-
"""ML_project_20ng_final_11231151.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Si1kx_L-lzLNtcq2teq9r_mkE5XApU1j

# 1) Data loading and dataset preparation

*italicized text*###       a) To read and trim the text data (create a list of categories)
"""

path = '/20NG-all-terms.txt'
op = open(path, 'r')

D1 = []
for Text_Label in op:
    D1.append(Text_Label.rstrip())

print(len(D1), '\n')
D1

for i, T in enumerate(D1[:3]):
    print(i, '\n', T, '\n')

"""### b) Creation of a data frame"""

import pandas as pd

Data_frame = pd.read_csv(path, sep='\t', names=['Category', 'Article'])
Data_frame

"""# 2) Descriptive statistics of the text data

### a) Categories counts
"""

DS = Data_frame.describe()
DS.to_csv('01_Descriptive_stat.csv')
DS

DFC = Data_frame.groupby('Category').describe()
DFC.to_csv('02_Descriptive_stat.csv')
DFC

"""### b) Length of the articles"""

Data_frame['Article_length'] = Data_frame['Article'].apply(len)
Data_frame

"""### c) Histogram and statistics of the articles' lengths"""

import matplotlib.pyplot as plt
import seaborn as sns

# % matplotlib inline

dist_p = sns.distplot(Data_frame['Article_length'], bins=50)
dp = dist_p.get_figure()
plt.title('Histogram of the articles length')
# dp.savefig('Hist_01.png',dpi=600)

Data_frame['Article_length'].describe()

hist = Data_frame.hist(column='Article_length', by='Category', bins=100, figsize=(20, 15))
plt.savefig('Hist_02.png', dpi=800)

"""# 3) Tokenization of the texts

### To create a function for : a) Punctuation removal b) Stopwords eliminations c) returning cleaned texts
"""

import string
# print (string.punctuation)
import nltk
from nltk.corpus import stopwords


# print (stopwords.words('english'))

def tokenization(Article):
    # step 1: punctuation removal
    No_punc = []
    for word in Article:
        if word not in string.punctuation:
            No_punc.append(word)

    No_punc = ''.join(No_punc)
    No_punc = No_punc.split()

    # step 2: stopwords removal
    No_stopw = []
    for txt in No_punc:
        if txt.lower() not in stopwords.words('english'):
            No_stopw.append(txt)

    # step 3: returning a cleaned data (without punctuations or stopwords)
    return No_stopw


"""# 4) Feature engineering 
###  a) Creation of the dictionary of words (bags of words) - Fit the text data
"""

Vocabularies_all = BoW_fit.vocabulary_
print(len(Vocabularies_all), '\n')
print(Vocabularies_all)

"""### b) BoW sparse matrix - Transform the text data to numerical values"""

Total_instances_BoW = BoW_SparseMatrix_tr.shape[0] * BoW_SparseMatrix_tr.shape[1]
Sp_BoW = (BoW_SparseMatrix_tr.nnz / Total_instances_BoW) * 100

print('BoW sparse matrix shape   = ', BoW_SparseMatrix_tr.shape, '\n')
print('Total number of instances =', Total_instances_BoW, '\n')
print('BoW sparse matrix non-zero instances =', BoW_SparseMatrix_tr.nnz, '\n')
print('Sparsity of the matrix    =', Sp_BoW, '\n')

# print ('Bags-of-Words matrix :\n' , '\n' , BoW_SparseMatrix_tr)

Vocabularies_all_TFIDF_Vec = TFIDF_Vec_fit.vocabulary_

print(len(Vocabularies_all_TFIDF_Vec), '\n')
print(Vocabularies_all_TFIDF_Vec)

"""# 5) Model trainings

### a) Train-test split : setting 60% for train - 25% for validation - 15% for test
"""

from sklearn.cross_validation import train_test_split

Train_Data_X, ValidTest_Data_X, Train_Data_Y, ValidTest_Data_Y = train_test_split(Data_frame['Article'],
                                                                                  Data_frame['Category'], test_size=0.4)

Valid_Data_X, Test_Data_X, Valid_Data_Y, Test_Data_Y = train_test_split(ValidTest_Data_X, ValidTest_Data_Y,
                                                                        test_size=0.3)

"""### b) Calling ML classification models"""

# ML model 1 : Multinomial Naive Bayes
from sklearn.naive_bayes import MultinomialNB

# ML model 3 : Random Forest classifier
from sklearn.ensemble import RandomForestClassifier

# ML model 4 : SVM classifier
from sklearn import svm

import time

"""# +++++++++++++++++++++ Model using pipeline ++++++++++++++++++++++

### c-1-1) Creating pipelines : Train Naive-Bayes / Bag of Words - fit the models
"""

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer

# to train : BoW features / Naive Bayes method

### Naive_Bayes with Alpha = 10
Pipe_1_BoW_NB_alpha_10 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization, encoding='utf-8')),
    ('1_NB_Alph_10', MultinomialNB(alpha=10))
])

### Naive_Bayes with Alpha = 0.0001
Pipe_1_BoW_NB_alpha_0001 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization, encoding='utf-8')),
    ('1_NB_Alph_0.0001', MultinomialNB(alpha=0.0001))
])

# Fit the models - BoW / NB alpha = 10
start_time = time.time()
Pipe_1_BoW_NB_alpha_10.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - BoW / NB alpha = 0.0001
start_time = time.time()
Pipe_1_BoW_NB_alpha_0001.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-1-1) To validate the BoW / NB models by validation set"""

# Predict the models by validation set - BoW / NB alpha = 10
start_time = time.time()
NB_BoW_alph_10_valid = Pipe_1_BoW_NB_alpha_10.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - BoW / NB alpha = 0.0001
start_time = time.time()
NB_BoW_alph_0001_valid = Pipe_1_BoW_NB_alpha_0001.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-1-1) To report the BoW / NB models by test set"""

# Predict the models by test set - BoW / NB alpha = 10
start_time = time.time()
NB_BoW_alph_10_test = Pipe_1_BoW_NB_alpha_10.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - BoW / NB alpha = 0.0001
start_time = time.time()
NB_BoW_alph_0001_test = Pipe_1_BoW_NB_alpha_0001.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-1-1) Performances : confusion matrix - BoW / NB

#### ** Validation
"""

# Alpha 10
from sklearn.metrics import confusion_matrix
import seaborn as sns

NB_BoW_alph_10_valid_ConfMat = confusion_matrix(NB_BoW_alph_10_valid, Valid_Data_Y)
print('Confusion matrix : BoW / Naive Bayes - Alpha = 10\n', '\n', NB_BoW_alph_10_valid_ConfMat)
HM_valid_BoW_NB_alph_10 = sns.heatmap(NB_BoW_alph_10_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                      linewidth=2)
plt.title('Naive Bayes / BoW : Alpha = 10')
plt.savefig('HM_valid_BoW_NB_alph_10.png', dpi=600)

# Classification reports
from sklearn.metrics import classification_report

NB_BoW_alph_10_valid_report = classification_report(NB_BoW_alph_10_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_BoW_alph_10_valid_report)

# Alpha 0.0001
NB_BoW_alph_0001_valid_ConfMat = confusion_matrix(NB_BoW_alph_0001_valid, Valid_Data_Y)
print('Confusion matrix : BoW / Naive Bayes - Alpha = 0.0001\n', '\n', NB_BoW_alph_0001_valid_ConfMat)
HM_valid_BoW_NB_alph_0001 = sns.heatmap(NB_BoW_alph_0001_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                        linewidth=2)
plt.title('Naive Bayes / BoW - Alpha = 0.0001')
plt.savefig('HM_valid_BoW_NB_alph_0001.png', dpi=600)

# Classification reports

NB_BoW_alph_0001_valid_report = classification_report(NB_BoW_alph_0001_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_BoW_alph_0001_valid_report)

"""#### ** Test"""

# Alpha 10
NB_BoW_alph_10_test_ConfMat = confusion_matrix(NB_BoW_alph_10_test, Test_Data_Y)
print('Confusion matrix : BoW / Naive Bayes Alpha = 10 \n', '\n', NB_BoW_alph_10_test_ConfMat)
HM_test_BoW_NB_alph_10 = sns.heatmap(NB_BoW_alph_10_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                     linewidth=2)
plt.title('Naive Bayes / BoW : Alpha = 10')
plt.savefig('HM_test_BoW_NB_alph_10.png', dpi=600)

# Classification reports
NB_BoW_alph_10_test_report = classification_report(NB_BoW_alph_10_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_BoW_alph_10_test_report)

# Alpha 0.0001
NB_BoW_alph_0001_test_ConfMat = confusion_matrix(NB_BoW_alph_0001_test, Test_Data_Y)
print('Confusion matrix : BoW / Naive Bayes - Alpha = 0.0001\n', '\n', NB_BoW_alph_0001_test_ConfMat)
HM_test_BoW_NB_alph_0001 = sns.heatmap(NB_BoW_alph_0001_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                       linewidth=2)
plt.title('Naive Bayes / BoW : Alpha = 0.0001')
plt.savefig('HM_test_BoW_NB_alph_0001.png', dpi=600)

# Classification reports
NB_BoW_alph_0001_test_report = classification_report(NB_BoW_alph_0001_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_BoW_alph_0001_test_report)

"""### c-2-1) Creating pipelines : Train Naive-Bayes / TFIDF - fit the models"""

# to train : TFIDF / Naive Bayes method

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer

### Naive_Bayes with Alpha = 10
Pipe_2_TFIDF_NB_alph_10 = Pipeline([
    ('2_TFIDF_fit', TfidfVectorizer(analyzer=tokenization)),
    ('2_TFIDF', TfidfTransformer()),
    ('1_NB_Alph_10', MultinomialNB(alpha=10))
])

### Naive_Bayes with Alpha = 0.001
Pipe_2_TFIDF_NB_alph_0001 = Pipeline([
    ('2_TFIDF_fit', TfidfVectorizer(analyzer=tokenization)),
    ('2_TFIDF', TfidfTransformer()),
    ('1_NB_Alph_0001', MultinomialNB(alpha=0.0001))
])

# Fit the models - TFIDF / NB alpha = 10
start_time = time.time()
Pipe_2_TFIDF_NB_alph_10.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - TFIDF / NB alpha = 0.0001
start_time = time.time()
Pipe_2_TFIDF_NB_alph_0001.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-2-1) To validate the TFIDF / NB models by validation set"""

# Predict the models by validation set - TFIDF / NB alpha = 10
start_time = time.time()
NB_TFIDF_alph_10_valid = Pipe_2_TFIDF_NB_alph_10.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - TFIDF / NB alpha = 0.0001
start_time = time.time()
NB_TFIDF_alph_0001_valid = Pipe_2_TFIDF_NB_alph_0001.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-2-1) To report the TFIDF / NB models by test set"""

# Predict the models by test set - TFIDF / NB alpha = 10
start_time = time.time()
NB_TFIDF_alph_10_test = Pipe_2_TFIDF_NB_alph_10.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - TFIDF / NB alpha = 0.0001
start_time = time.time()
NB_TFIDF_alph_0001_test = Pipe_2_TFIDF_NB_alph_0001.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-2-1) Performances : confusion matrix - TFIDF / NB

#### ** Validation
"""

# Alpha 10
NB_TFIDF_alph_10_valid_ConfMat = confusion_matrix(NB_TFIDF_alph_10_valid, Valid_Data_Y)
print('Confusion matrix : TFIDF / Naive Bayes - Alpha = 10 \n', '\n', NB_TFIDF_alph_10_valid_ConfMat)
HM_valid_TFIDF_NB_alph_10 = sns.heatmap(NB_TFIDF_alph_10_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                        linewidth=2)
plt.title('Naive Bayes / TFIDF : Alpha=10')
plt.savefig('HM_valid_TFIDF_NB_alph_10.png', dpi=600)

# Classification reports
NB_TFIDF_alph_10_valid_report = classification_report(NB_TFIDF_alph_10_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_TFIDF_alph_10_valid_report)

# Alpha 0.0001
NB_TFIDF_alph_0001_valid_ConfMat = confusion_matrix(NB_TFIDF_alph_0001_valid, Valid_Data_Y)
print('Confusion matrix : TFIDF / Naive Bayes - Alpha = 0.0001 \n', '\n', NB_TFIDF_alph_0001_valid_ConfMat)
HM_valid_TFIDF_NB_alph_0001 = sns.heatmap(NB_TFIDF_alph_0001_valid_ConfMat, annot=False, cmap='coolwarm',
                                          linecolor='black', linewidth=2)
plt.title('Naive Bayes / TFIDF : Alpha=0.0001')
plt.savefig('HM_valid_TFIDF_NB_alph_0001.png', dpi=600)

# Classification reports
NB_TFIDF_alph_0001_valid_report = classification_report(NB_TFIDF_alph_0001_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_TFIDF_alph_0001_valid_report)

"""#### ** Test"""

# Alpha 10
NB_TFIDF_alph_10_test_ConfMat = confusion_matrix(NB_TFIDF_alph_10_test, Test_Data_Y)
print('Confusion matrix : TFIDF / Naive Bayes Alpha = 10\n', '\n', NB_TFIDF_alph_10_test_ConfMat)
HM_test_TFIDF_NB_alph_10 = sns.heatmap(NB_TFIDF_alph_10_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                       linewidth=2)
plt.title('Naive Bayes / TFIDF - Alpha = 10')
plt.savefig('HM_test_TFIDF_NB_alph_10.png', dpi=600)

# Classification reports
NB_TFIDF_alph_10_test_report = classification_report(NB_TFIDF_alph_10_test, Test_Data_Y)
print('Classification report : TFIDF / Naive Bayes \n', '\n', NB_TFIDF_alph_10_test_report)

# Alpha 0.0001
NB_TFIDF_alph_0001_test_ConfMat = confusion_matrix(NB_TFIDF_alph_0001_test, Test_Data_Y)
print('Confusion matrix : TFIDF / Naive Bayes Alpha = 0.0001\n', '\n', NB_TFIDF_alph_0001_test_ConfMat)
HM_test_TFIDF_NB_alph_0001 = sns.heatmap(NB_TFIDF_alph_0001_test_ConfMat, annot=False, cmap='coolwarm',
                                         linecolor='black', linewidth=2)
plt.title('Naive Bayes / TFIDF - Alpha = 0.0001')
plt.savefig('HM_test_TFIDF_NB_alph_0001.png', dpi=600)

# Classification reports
NB_TFIDF_alph_0001_test_report = classification_report(NB_TFIDF_alph_0001_test, Test_Data_Y)
print('Classification report : TFIDF / Naive Bayes \n', '\n', NB_TFIDF_alph_0001_test_report)

"""### c-3-1) Creating pipelines : Train Naive-Bayes / Dirichlet - fit the models"""

# to train : Drichlet features / Naive Bayes method
from sklearn.decomposition import LatentDirichletAllocation

### Dirichlet with 50 topics - Naive_Bayes with Alpha = 0.0001
Pipe_3_Drch_50_NB_0001 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat', LatentDirichletAllocation(n_topics=50, max_iter=15, learning_method='online', learning_offset=50.,
                                                random_state=0)),
    ('1_NB_alph_1', MultinomialNB(alpha=0.0001))
])

### Dirichlet with 200 topics - Naive_Bayes with Alpha = 0.0001
Pipe_3_Drch_200_NB_0001 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat',
     LatentDirichletAllocation(n_topics=200, max_iter=15, learning_method='online', learning_offset=50.,
                               random_state=0)),
    ('1_NB_alph_1', MultinomialNB(alpha=0.0001))
])

# Fit the models - Dirichlet 50 / NB alpha = 0.0001
start_time = time.time()
Pipe_3_Drch_50_NB_0001.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - Dirichlet 200 / NB alpha = 0.0001
start_time = time.time()
Pipe_3_Drch_200_NB_0001.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-3-1) To validate the Dirichlet / NB models by validation set"""

# Predict the models by validation set - Dirichlet topics = 50 / NB alpha = 0.0001
start_time = time.time()
NB_Drch_50_valid = Pipe_3_Drch_50_NB_0001.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - Dirichlet topics = 200 / NB alpha = 0.0001
start_time = time.time()
NB_Drch_200_valid = Pipe_3_Drch_200_NB_0001.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-3-1) To report the Dirichlet / NB models by test set"""

# Predict the models by test set - Dirichlet topics = 50 / NB alpha = 0.0001
start_time = time.time()
NB_Drch_50_test = Pipe_3_Drch_50_NB_0001.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - Dirichlet topics = 200 / NB alpha = 0.0001
start_time = time.time()
NB_Drch_200_test = Pipe_3_Drch_200_NB_0001.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-3-1) Performances : confusion matrix - Dirichlet / NB

#### ** Validation
"""

# Topic = 50 - Alpha = 0.0001
NB_Drch_50_valid_ConfMat = confusion_matrix(NB_Drch_50_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet topic=50 / Naive Bayes - Alpha = 0.0001 \n', '\n', NB_Drch_50_valid_ConfMat)
HM_valid_Drch_50_valid = sns.heatmap(NB_Drch_50_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                     linewidth=2)
plt.title('Naive Bayes/LDA:topics=50,Alpha=0.0001')
plt.savefig('HM_valid_Drch_50_NB_0001.png', dpi=600)

# Classification reports
NB_Drch_50_valid_report = classification_report(NB_Drch_50_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_Drch_50_valid_report)

# Topic = 50 - Alpha = 0.0001
NB_Drch_200_valid_ConfMat = confusion_matrix(NB_Drch_200_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet topic=200 / Naive Bayes - Alpha = 0.0001 \n', '\n', NB_Drch_200_valid_ConfMat)
HM_valid_Drch_200_valid = sns.heatmap(NB_Drch_200_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                      linewidth=2)
plt.title('Naive Bayes/LDA:topics=200,Alpha=0.0001')
plt.savefig('HM_valid_Drch_200_NB_0001.png', dpi=600)

# Classification reports
NB_Drch_200_valid_report = classification_report(NB_Drch_200_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_Drch_200_valid_report)

"""#### ** Test"""

# Topic = 50 - Alpha = 0.0001
NB_Drch_50_NB_test_ConfMat = confusion_matrix(NB_Drch_50_test, Test_Data_Y)
print('Confusion matrix : Dirichlet topic = 50 / Naive Bayes Alpha = 0.0001\n', '\n', NB_Drch_50_NB_test_ConfMat)
HM_test_Drch_50_NB = sns.heatmap(NB_Drch_50_NB_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                 linewidth=2)
plt.title('Naive Bayes/LDA:topic=50 Alpha = 0.0001')
plt.savefig('HM_test_Drch_50_NB_alph_0001.png', dpi=600)

# Classification reports
NB_Drch_50_test_report = classification_report(NB_Drch_50_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_Drch_50_test_report)

# Topic = 200 - Alpha = 0.0001
NB_Drch_200_NB_test_ConfMat = confusion_matrix(NB_Drch_200_test, Test_Data_Y)
print('Confusion matrix : Dirichlet topic = 200 / Naive Bayes Alpha = 0.0001\n', '\n', NB_Drch_200_NB_test_ConfMat)
HM_test_Drch_200_NB = sns.heatmap(NB_Drch_200_NB_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                  linewidth=2)
plt.title('Naive Bayes/LDA:topic=200 Alpha=0.0001')
plt.savefig('HM_test_Drch_200_NB_alph_0001.png', dpi=600)

# Classification reports
NB_Drch_200_test_report = classification_report(NB_Drch_200_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NB_Drch_200_test_report)

"""### c-1-2) Creating pipelines : Train Random forest / BoW features - fit the models"""

# to train : BoW features / Random Forest method

# to train : Random forest estimator = 30 - Gini
Pipe_4_BoW_RF_30_gn = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('2_RF_model', RandomForestClassifier(n_estimators=30, criterion='gini'))
])

# to train : Random forest estimator = 50 - Entropy
Pipe_4_BoW_RF_60_ent = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('2_RF_model', RandomForestClassifier(n_estimators=60, criterion='entropy'))
])

# Fit the models - Random forest estimator = 30 - Gini
start_time = time.time()
Pipe_4_BoW_RF_30_gn.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - Random forest estimator = 60 - Entropy
start_time = time.time()
Pipe_4_BoW_RF_60_ent.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-1-2) To validate the BoW / RF models by validation set"""

# Predict the models by validation set - BoW / RF estomator = 30 - Gini
start_time = time.time()
RF_BoW_30_gn_valid = Pipe_4_BoW_RF_30_gn.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - BoW / RF estomator = 60 - Entropy
start_time = time.time()
RF_BoW_60_ent_valid = Pipe_4_BoW_RF_60_ent.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-1-2) To report the BoW/ RF models by test set"""

# Predict the models by test set - BoW / RF estimator = 30 - Gini
start_time = time.time()
RF_BoW_30_gn_test = Pipe_4_BoW_RF_30_gn.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - BoW / RF estimator = 30 - Entropy
start_time = time.time()
RF_BoW_60_ent_test = Pipe_4_BoW_RF_60_ent.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-1-2) Performances : confusion matrix - BoW / RF

#### ** Validation
"""

# Estimator = 30 - Gini
RF_BoW_30_gn_valid_ConfMat = confusion_matrix(RF_BoW_30_gn_valid, Valid_Data_Y)
print('Confusion matrix : BoW / RF Estimator = 30 - Gini \n', '\n', RF_BoW_30_gn_valid_ConfMat)
HM_valid_BoW_RF_30_gn_valid = sns.heatmap(RF_BoW_30_gn_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('Random Forest: Est=30 -Gini / BoW')
plt.savefig('HM_valid_BoW_RF_30_gn.png', dpi=600)

# Classification reports
RF_BoW_30_gn_valid_report = classification_report(RF_BoW_30_gn_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_BoW_30_gn_valid_report)

# Estimator = 60 - Entropy
RF_BoW_60_ent_valid_ConfMat = confusion_matrix(RF_BoW_60_ent_valid, Valid_Data_Y)
print('Confusion matrix : BoW / RF Estimator = 60 - Entropy \n', '\n', RF_BoW_60_ent_valid_ConfMat)
HM_valid_BoW_RF_60_ent_valid = sns.heatmap(RF_BoW_60_ent_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                           linewidth=2)
plt.title('Random Forest: Est=60 -Entropy / BoW')
plt.savefig('HM_valid_BoW_RF_60_entropy.png', dpi=600)

# Classification reports
RF_BoW_60_ent_valid_report = classification_report(RF_BoW_60_ent_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_BoW_60_ent_valid_report)

"""#### ** Test"""

# Estimator = 30 - Gini
RF_BoW_30_gn_test_ConfMat = confusion_matrix(RF_BoW_30_gn_test, Test_Data_Y)
print('Confusion matrix : BoW / RF Estimator = 30 - Gini \n', '\n', RF_BoW_30_gn_test_ConfMat)
HM_test_BoW_RF_30_gn_test = sns.heatmap(RF_BoW_30_gn_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                        linewidth=2)
plt.title('Random Forest: Est=30 -Gini / BoW')
plt.savefig('HM_test_BoW_RF_30_gn.png', dpi=600)

# Classification reports
RF_BoW_30_gn_test_report = classification_report(RF_BoW_30_gn_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_BoW_30_gn_test_report)

# Estimator = 60 - Entropy
RF_BoW_60_ent_test_ConfMat = confusion_matrix(RF_BoW_60_ent_test, Test_Data_Y)
print('Confusion matrix : BoW / RF Estimator = 60 - Entropy \n', '\n', RF_BoW_60_ent_test_ConfMat)
HM_valid_BoW_RF_60_ent_test = sns.heatmap(RF_BoW_60_ent_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('Random Forest: Est=60 -Entropy / BoW')
plt.savefig('HM_test_BoW_RF_60_entropy.png', dpi=600)

# Classification reports
RF_BoW_60_ent_test_report = classification_report(RF_BoW_60_ent_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_BoW_60_ent_test_report)

"""### c-2-2) Creating pipelines : Train Random forest / TFIDF features - fit the models"""

# to train : TFIDF features / Random Forest method

# to train : Random forest estimator = 30 - Gini
Pipe_5_TFIDF_RF_30_gn = Pipeline([
    ('2_TFIDF_fit', TfidfVectorizer(analyzer=tokenization)),
    ('2_TFIDF_SpMat', TfidfTransformer()),
    ('2_RF_model', RandomForestClassifier(n_estimators=30, criterion='gini'))
])

# to train : Random forest estimator = 60 - Entropy
Pipe_5_TFIDF_RF_60_ent = Pipeline([
    ('2_TFIDF_fit', TfidfVectorizer(analyzer=tokenization)),
    ('2_TFIDF_SpMat', TfidfTransformer()),
    ('2_RF_model', RandomForestClassifier(n_estimators=60, criterion='entropy'))
])

# Fit the models - Random forest estimator = 30 - Gini
start_time = time.time()
Pipe_5_TFIDF_RF_30_gn.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - Random forest estimator = 60 - Entropy
start_time = time.time()
Pipe_5_TFIDF_RF_60_ent.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-2-2) To validate the TFIDF / RF models by validation set"""

# Predict the models by validation set - TFIDF / RF estomator = 30 - Gini
start_time = time.time()
RF_TFIDF_30_gn_valid = Pipe_5_TFIDF_RF_30_gn.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - TFIDF / RF estomator = 60 - Entropy
start_time = time.time()
RF_TFIDF_60_ent_valid = Pipe_5_TFIDF_RF_60_ent.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-2-2) To report the TFIDF /  RF models by test set"""

# Predict the models by test set - TFIDF / RF estimator = 30 - Gini
start_time = time.time()
RF_TFIDF_30_gn_test = Pipe_5_TFIDF_RF_30_gn.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - TFIDF / RF estimator = 60 - Entropy
start_time = time.time()
RF_TFIDF_60_ent_test = Pipe_5_TFIDF_RF_60_ent.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-2-2) Performances : confusion matrix - TFIDF / RF

#### ** Validation
"""

from sklearn.metrics import confusion_matrix

# Estimator = 30 - Gini
RF_TFIDF_30_gn_valid_ConfMat = confusion_matrix(RF_TFIDF_30_gn_valid, Valid_Data_Y)
print('Confusion matrix : TFIDF / RF Estimator = 30 - Gini \n', '\n', RF_TFIDF_30_gn_valid_ConfMat)
HM_valid_TFIDF_RF_30_gn_valid = sns.heatmap(RF_TFIDF_30_gn_valid_ConfMat, annot=False, cmap='coolwarm',
                                            linecolor='black', linewidth=2)
plt.title('Random Forest: Est=30 -Gini / TFIDF')
plt.savefig('HM_valid_TFIDF_RF_30_gn.png', dpi=600)

# Classification reports
RF_TFIDF_30_gn_valid_report = classification_report(RF_TFIDF_30_gn_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_TFIDF_30_gn_valid_report)

# Estimator = 60 - Entropy
RF_TFIDF_60_ent_valid_ConfMat = confusion_matrix(RF_TFIDF_60_ent_valid, Valid_Data_Y)
print('Confusion matrix : TFIDF / RF Estimator = 60 - Entropy \n', '\n', RF_TFIDF_60_ent_valid_ConfMat)
HM_valid_TFIDF_RF_60_ent_valid = sns.heatmap(RF_TFIDF_60_ent_valid_ConfMat, annot=False, cmap='coolwarm',
                                             linecolor='black', linewidth=2)
plt.title('Random Forest: Est=60 -Entropy / TFIDF')
plt.savefig('HM_valid_TFIDF_RF_60_entropy.png', dpi=600)

# Classification reports
RF_TFIDF_60_ent_valid_report = classification_report(RF_TFIDF_60_ent_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_TFIDF_60_ent_valid_report)

"""#### ** Test"""

# Estimator = 30 - Gini
RF_TFIDF_30_gn_test_ConfMat = confusion_matrix(RF_TFIDF_30_gn_test, Test_Data_Y)
print('Confusion matrix : TFIDF / RF Estimator = 30 - Gini \n', '\n', RF_TFIDF_30_gn_test_ConfMat)
HM_test_TFIDF_RF_30_gn_test = sns.heatmap(RF_TFIDF_30_gn_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('Random Forest: Est=30 -Gini / TFIDF')
plt.savefig('HM_test_TFIDF_RF_30_gn.png', dpi=600)

# Classification reports
RF_TFIDF_30_gn_test_report = classification_report(RF_TFIDF_30_gn_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_TFIDF_30_gn_test_report)

# Estimator = 60 - Entropy
RF_TFIDF_60_ent_test_ConfMat = confusion_matrix(RF_TFIDF_60_ent_test, Test_Data_Y)
print('Confusion matrix : TFIDF / RF Estimator = 60 - Entropy \n', '\n', RF_TFIDF_60_ent_test_ConfMat)
HM_valid_TFIDF_RF_60_ent_test = sns.heatmap(RF_TFIDF_60_ent_test_ConfMat, annot=False, cmap='coolwarm',
                                            linecolor='black', linewidth=2)
plt.title('Random Forest: Est=60 -Entropy / TFIDF')
plt.savefig('HM_test_TFIDF_RF_60_entropy.png', dpi=600)

# Classification reports
RF_TFIDF_60_ent_test_report = classification_report(RF_TFIDF_60_ent_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_TFIDF_60_ent_test_report)

"""### c-2-3) Creating pipelines : Train Random Forest / Dirichlet - fit the models"""

# to train : Drichlet features / Random Forest method

### Dirichlet with 50 topics - Random forest estimator = 30 - Gini
Pipe_6_Drch_50_RF_30_gn = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat', LatentDirichletAllocation(n_topics=50, max_iter=15, learning_method='online', learning_offset=50.,
                                                random_state=0)),
    ('2_RF_model', RandomForestClassifier(n_estimators=30, criterion='gini'))
])

### Dirichlet with 200 topics - Random forest estimator = 60 - Entropy
Pipe_6_Drch_1000_RF_60_ent = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat',
     LatentDirichletAllocation(n_topics=200, max_iter=10, learning_method='online', learning_offset=50.,
                               random_state=0)),
    ('2_RF_model', RandomForestClassifier(n_estimators=60, criterion='entropy'))
])

# Fit the models - Dirichlet 50 topics / Random forest estimator = 30 - Gini
start_time = time.time()
Pipe_6_Drch_50_RF_30_gn.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - Dirichlet 200 topics / Random forest estimator = 60 - Entropy
start_time = time.time()
Pipe_6_Drch_1000_RF_60_ent.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-2-3) To validate the Dirichlet / RF models by validation set"""

# Predict the models by validation set - Dirichlet 50 topics / RF estomator = 30 - Gini
start_time = time.time()
RF_Drch_50_30_gn_valid = Pipe_6_Drch_50_RF_30_gn.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - Dirichlet 200 topics / RF estomator = 60 - Entropy
start_time = time.time()
RF_Drch_1000_60_ent_valid = Pipe_6_Drch_1000_RF_60_ent.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-2-3) To report the Dirichlet /  RF models by test set"""

# Predict the models by test set - Dirichlet 50 topics / RF estimator = 30 - Gini
start_time = time.time()
RF_Drch_50_30_gn_test = Pipe_6_Drch_50_RF_30_gn.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - Dirichet 200 topics / RF estimator = 60 - Entropy
start_time = time.time()
RF_Drch_1000_60_ent_test = Pipe_6_Drch_1000_RF_60_ent.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-2-3) Performances : confusion matrix - Dirichlet / RF

#### ** Validation
"""

# 50 topics / Estimator = 30 - Gini
RF_Drch_50_30_gn_valid_ConfMat = confusion_matrix(RF_Drch_50_30_gn_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet 50 topics / RF Estimator = 30 - Gini \n', '\n', RF_Drch_50_30_gn_valid_ConfMat)
HM_valid_Drch_50_RF_30_gn_valid = sns.heatmap(RF_Drch_50_30_gn_valid_ConfMat, annot=False, cmap='coolwarm',
                                              linecolor='black', linewidth=2)
plt.title('Random Forest:Est=30-Gini/LDA 50 topics')
plt.savefig('HM_valid_Drch_50_RF_30_gn.png', dpi=600)

# Classification reports
RF_Drch_50_30_gn_valid_report = classification_report(RF_Drch_50_30_gn_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_Drch_50_30_gn_valid_report)

# 200 topics / Estimator = 60 - Entropy
RF_Drch_1000_60_ent_valid_ConfMat = confusion_matrix(RF_Drch_1000_60_ent_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet 1000 topics / RF Estimator = 60 - Entropy \n', '\n',
      RF_Drch_1000_60_ent_valid_ConfMat)
HM_valid_Drch_1000_RF_60_ent_valid = sns.heatmap(RF_Drch_1000_60_ent_valid_ConfMat, annot=False, cmap='coolwarm',
                                                 linecolor='black', linewidth=2)
plt.title('Random Forest:Est=60-Entropy/LDA 200 topics')
plt.savefig('HM_valid_Drch_1000_RF_60_ent.png', dpi=600)

# Classification reports
RF_Drch_1000_60_ent_valid_report = classification_report(RF_Drch_1000_60_ent_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_Drch_1000_60_ent_valid_report)

"""#### ** Test"""

# 50 topics / Estimator = 30 - Gini
RF_Drch_50_30_gn_test_ConfMat = confusion_matrix(RF_Drch_50_30_gn_test, Test_Data_Y)
print('Confusion matrix : Dirichlet 50 topics / RF Estimator = 30 - Gini \n', '\n', RF_Drch_50_30_gn_test_ConfMat)
HM_test_Drch_50_RF_30_gn_test = sns.heatmap(RF_Drch_50_30_gn_test_ConfMat, annot=False, cmap='coolwarm',
                                            linecolor='black', linewidth=2)
plt.title('Random Forest:Est=30-Gini/LDA 50 topics')
plt.savefig('HM_test_TDrch_50_RF_30_gn.png', dpi=600)

# Classification reports
RF_Drch_50_30_gn_test_report = classification_report(RF_Drch_50_30_gn_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_Drch_50_30_gn_test_report)

# 200 topics / Estimator = 60 - Entropy
RF_Drch_1000_60_ent_test_ConfMat = confusion_matrix(RF_Drch_1000_60_ent_test, Test_Data_Y)
print('Confusion matrix : Dirichlet 1000 topics / RF Estimator = 60 - Entropy \n', '\n',
      RF_Drch_1000_60_ent_test_ConfMat)
HM_test_Drch_50_RF_60_ent_test = sns.heatmap(RF_Drch_1000_60_ent_test_ConfMat, annot=False, cmap='coolwarm',
                                             linecolor='black', linewidth=2)
plt.title('Random Forest:Est=60-Entropy/LDA 200 topics')
plt.savefig('HM_test_TDrch_50_RF_60_ent.png', dpi=600)

# Classification reports
RF_Drch_1000_60_ent_test_report = classification_report(RF_Drch_1000_60_ent_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', RF_Drch_1000_60_ent_test_report)

"""### c-3-1) Creating pipelines : Train Support Vector Machine / BoW features - fit the models"""

# to train : BoW features / Support Vector Machine method

from sklearn.pipeline import Pipeline

### to train : SVM - Kernel=linear tol=1 x 10^-4
Pipe_7_BoW_svm_lin_t4 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_SVM_model', svm.SVC(C=1.0, kernel='linear', tol=0.0001))
])

### to train : SVM - Kernel=rbf gamma=0.0001 tol=1 x 10^-7
Pipe_7_BoW_svm_rbf_g0001_t7 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_SVM_model', svm.SVC(C=1.0, kernel='rbf', gamma=0.0001, tol=0.0000001))
])

# Fit the models - SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
Pipe_7_BoW_svm_lin_t4.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - SVM - Kernel=rbf gamma=0.0001 tol=1 x 10^-7
start_time = time.time()
Pipe_7_BoW_svm_rbf_g0001_t7.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-3-1) To validate the BoW / SVM models by validation set"""

# Predict the models by validation set - BoW / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
SVM_BoW_lin_t4_valid = Pipe_7_BoW_svm_lin_t4.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - BoW / SVM - Kernel=rbf gamma=0.0001 tol=1 x 10^-7
start_time = time.time()
SVM_BoW_rbf_g0001_t7_valid = Pipe_7_BoW_svm_rbf_g0001_t7.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-3-1) To report the BoW / SVM models by test set"""

# Predict the models by test set - BoW / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
SVM_BoW_lin_t4_test = Pipe_7_BoW_svm_lin_t4.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - BoW / SVM - Kernel=rbf gamma=0.0001 tol=1 x 10^-7
start_time = time.time()
SVM_BoW_rbf_g0001_t7_test = Pipe_7_BoW_svm_rbf_g0001_t7.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-3-1) Performances : confusion matrix - BoW / SVM

#### ** Validation
"""

# BoW / SVM - Kernel=linear tol=1 x 10^-4
SVM_BoW_lin_t4_valid_ConfMat = confusion_matrix(SVM_BoW_lin_t4_valid, Valid_Data_Y)
print('Confusion matrix : BoW / SVM - Kernel=linear tol=1 x 10^-4 \n', '\n', SVM_BoW_lin_t4_valid_ConfMat)
HM_valid_SVM_BoW_lin_t4_valid = sns.heatmap(SVM_BoW_lin_t4_valid_ConfMat, annot=False, cmap='coolwarm',
                                            linecolor='black', linewidth=2)
plt.title('SVM - Kernel=linear tol=1 x 10^-4 / BoW')
plt.savefig('HM_valid_SVM_BoW_lin_t4.png', dpi=600)

# Classification reports
SVM_BoW_lin_t4_valid_report = classification_report(SVM_BoW_lin_t4_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_BoW_lin_t4_valid_report)

#  BoW / SVM - Kernel=rbf gamma=0.0001 tol=1 x 10^-7
SVM_BoW_rbf_g0001_t7_valid_ConfMat = confusion_matrix(SVM_BoW_rbf_g0001_t7_valid, Valid_Data_Y)
print('Confusion matrix : BoW / SVM - Kernel=rbf gamma=0.0001 tol=1 x 10^-7 \n', '\n',
      SVM_BoW_rbf_g0001_t7_valid_ConfMat)
HM_valid_SVM_BoW_rbf_g0001_t7_valid = sns.heatmap(SVM_BoW_rbf_g0001_t7_valid_ConfMat, annot=False, cmap='coolwarm',
                                                  linecolor='black', linewidth=2)
plt.title('SVM-Kern=rbf gam=0.0001 tol=10^-7/BoW')
plt.savefig('HM_valid_SVM_BoW_rbf_g0001_t7.png', dpi=600)

# Classification reports
SVM_BoW_rbf_g0001_t7_valid_report = classification_report(SVM_BoW_rbf_g0001_t7_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_BoW_rbf_g0001_t7_valid_report)

"""#### ** Test"""

# BoW / SVM - Kernel=linear tol=1 x 10^-4
SVM_BoW_lin_t4_test_ConfMat = confusion_matrix(SVM_BoW_lin_t4_test, Test_Data_Y)
print('Confusion matrix : BoW / RF Estimator = 30 - Gini \n', '\n', SVM_BoW_lin_t4_test_ConfMat)
HM_test_SVM_BoW_lin_t4_test = sns.heatmap(SVM_BoW_lin_t4_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('SVM - Kernel=linear tol=1 x 10^-4 / BoW')
plt.savefig('HM_test_SVM_BoW_lin_t4.png', dpi=600)

# Classification reports
SVM_BoW_lin_t4_test_report = classification_report(SVM_BoW_lin_t4_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_BoW_lin_t4_test_report)

#  BoW / SVM - Kernel=rbf gamma=0.0001 tol=1 x 10^-7
SVM_BoW_rbf_g0001_t7_test_ConfMat = confusion_matrix(SVM_BoW_rbf_g0001_t7_test, Test_Data_Y)
print('Confusion matrix : BoW / SVM - Kernel=rbf gamma=0.0001 tol=1 x 10^-7 \n', '\n',
      SVM_BoW_rbf_g0001_t7_test_ConfMat)
HM_test_SVM_BoW_rbf_g0001_t7_test = sns.heatmap(SVM_BoW_rbf_g0001_t7_test_ConfMat, annot=False, cmap='coolwarm',
                                                linecolor='black', linewidth=2)
plt.title('SVM-Ker=rbf gam=0.0001 tol=10^-7/BoW')
plt.savefig('HM_test_SVM_BoW_rbf_g0001_t7.png', dpi=600)

# Classification reports
SVM_BoW_rbf_g0001_t7_test_report = classification_report(SVM_BoW_rbf_g0001_t7_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_BoW_rbf_g0001_t7_test_report)

"""### c-3-2) Creating pipelines : Train Support Vector Machine / TFIDF features - fit the models"""

# to train : TFIDF features / Support Vector Machine method

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer

### to train : SVM - Kernel=linear tol=1 x 10^-4
Pipe_8_TFIDF_svm_lin_t4 = Pipeline([
    ('2_TFIDF_fit', TfidfVectorizer(analyzer=tokenization)),
    ('2_TFIDF_SpMat', TfidfTransformer()),
    ('3_svm_model', svm.SVC(C=1.0, kernel='linear', tol=0.0001))
])

# Fit the models SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
Pipe_8_TFIDF_svm_lin_t4.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-3-2) To validate the TFIDF / SVM models by validation set"""

# Predict the models by validation set - TFIDF / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
SVM_TFIDF_lin_t4_valid = Pipe_8_TFIDF_svm_lin_t4.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-3-2) To report the TFIDF / SVM models by test set"""

# Predict the models by test set - TFIDF / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
SVM_TFIDF_lin_t4_test = Pipe_8_TFIDF_svm_lin_t4.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-3-2) Performances : confusion matrix - TFIDF / SVM

#### ** Validation
"""

# TFIDF / SVM - Kernel=linear tol=1 x 10^-4
SVM_TFIDF_lin_t4_valid_ConfMat = confusion_matrix(SVM_TFIDF_lin_t4_valid, Valid_Data_Y)
print('Confusion matrix : TFIDF / SVM - Kernel=linear tol=1 x 10^-4 \n', '\n', SVM_TFIDF_lin_t4_valid_ConfMat)
HM_valid_SVM_TFIDF_lin_t4_valid = sns.heatmap(SVM_TFIDF_lin_t4_valid_ConfMat, annot=False, cmap='coolwarm',
                                              linecolor='black', linewidth=2)
plt.title('SVM - Kernel=linear tol=1 x 10^-4 / TFIDF')
plt.savefig('HM_valid_SVM_TFIDF_lin_t4.png', dpi=600)

# Classification reports
SVM_TFIDF_lin_t4_valid_report = classification_report(SVM_TFIDF_lin_t4_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_TFIDF_lin_t4_valid_report)

"""#### ** Test"""

# TFIDF / SVM - Kernel=linear tol=1 x 10^-4
SVM_TFIDF_lin_t4_test_ConfMat = confusion_matrix(SVM_TFIDF_lin_t4_test, Test_Data_Y)
print('Confusion matrix : TFIDF / RF Estimator = 30 - Gini \n', '\n', SVM_TFIDF_lin_t4_test_ConfMat)
HM_test_SVM_TFIDF_lin_t4_test = sns.heatmap(SVM_TFIDF_lin_t4_test_ConfMat, annot=False, cmap='coolwarm',
                                            linecolor='black', linewidth=2)
plt.title('SVM - Kernel=linear tol=1 x 10^-4 / TFIDF')
plt.savefig('HM_test_SVM_TFIDF_lin_t4.png', dpi=600)

# Classification reports
SVM_TFIDF_lin_t4_test_report = classification_report(SVM_TFIDF_lin_t4_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_TFIDF_lin_t4_test_report)

"""### c-3-3) Creating pipelines : Train Support Vector Machine / Dirichlet features - fit the models"""

# to train : Dirichlet features / Support Vector Machine method

from sklearn.decomposition import LatentDirichletAllocation

### Dirichlet 50 topics / SVM - Kernel=linear tol=1 x 10^-4
Pipe_9_Drch_50_svm_lin_t4 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat',
     LatentDirichletAllocation(n_components=50, max_iter=15, learning_method='online', learning_offset=50.,
                               random_state=0)),
    ('3_svm_model', svm.SVC(C=1.0, kernel='linear', tol=0.0001))
])

### Dirichlet 200 topics / SVM - Kernel=rbf gamma=100 tol=1 x 10^-7
Pipe_9_Drch_200_svm_rbf_g100_t7 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat',
     LatentDirichletAllocation(n_components=200, max_iter=15, learning_method='online', learning_offset=50.,
                               random_state=0)),
    ('3_svm_model', svm.SVC(C=1.0, kernel='rbf', gamma=100, tol=0.0000001))
])

### Dirichlet 1000 topics / SVM - Kernel=linear tol=1 x 10^-4
Pipe_9_Drch_1000_svm_lin_t4 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat',
     LatentDirichletAllocation(n_components=500, max_iter=5, learning_method='online', learning_offset=50.,
                               random_state=0)),
    ('3_svm_model', svm.SVC(C=1.0, kernel='linear', tol=0.0001))
])

# Fit the models - Dirichlet 50 topics / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
Pipe_9_Drch_50_svm_lin_t4.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models Dirichlet 200 topics / SVM - Kernel=rbf gamma=100 tol=1 x 10^-7
start_time = time.time()
Pipe_9_Drch_200_svm_rbf_g100_t7.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models Dirichlet 1000 topics / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
Pipe_9_Drch_1000_svm_lin_t4.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-3-3) To validate the Dirichlet / SVM models by validation set"""

# Predict the models by validation set - Dirichlet 50 topics / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
SVM_Drch_50_lin_t4_valid = Pipe_9_Drch_50_svm_lin_t4.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - Dirichlet 200 topics / SVM - Kernel=rbf gamma=100 tol=1 x 10^-7
start_time = time.time()
SVM_Drch_200_rbf_g100_t7_valid = Pipe_9_Drch_200_svm_rbf_g100_t7.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - Dirichlet 1000 topics / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
SVM_Drch_1000_lin_t4_valid = Pipe_9_Drch_1000_svm_lin_t4.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-3-3) To report the Dirichlet / SVM models by test set"""

# Predict the models by test set - Dirichlet 50 topics / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
SVM_Drch_50_lin_t4_test = Pipe_9_Drch_50_svm_lin_t4.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - Dirichlet 200 topics / SVM - Kernel=rbf gamma=100 tol=1 x 10^-7
start_time = time.time()
SVM_Drch_200_rbf_g100_t7_test = Pipe_9_Drch_200_svm_rbf_g100_t7.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - Dirichlet 1000 topics / SVM - Kernel=linear tol=1 x 10^-4
start_time = time.time()
SVM_Drch_1000_lin_t4_test = Pipe_9_Drch_1000_svm_lin_t4.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-3-3) Performances : confusion matrix - Dirichlet / SVM

#### ** Validation
"""

# Dirichlet 50 topics / SVM - Kernel=linear tol=1 x 10^-4
SVM_Drch_50_lin_t4_valid_ConfMat = confusion_matrix(SVM_Drch_50_lin_t4_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet 50 topics / SVM - Kernel=linear tol=1 x 10^-4 \n', '\n',
      SVM_Drch_50_lin_t4_valid_ConfMat)
HM_valid_SVM_Drch_50_lin_t4_valid = sns.heatmap(SVM_Drch_50_lin_t4_valid_ConfMat, annot=False, cmap='coolwarm',
                                                linecolor='black', linewidth=2)
plt.title('SVM-Ker=linear tol=10^-4/LDA 50 topics')
plt.savefig('HM_valid_SVM_Drch_50_lin_t4.png', dpi=600)

# Classification reports
SVM_Drch_50_lin_t4_valid_report = classification_report(SVM_Drch_50_lin_t4_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_Drch_50_lin_t4_valid_report)

# Dirichlet 200 topics / SVM - Kernel=rbf gamma=100 tol=1 x 10^-7
SVM_Drch_200_rbf_g100_t7_valid_ConfMat = confusion_matrix(SVM_Drch_200_rbf_g100_t7_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet 200 topics / SVM -Kernel=rbf gamma=100 tol=1 x 10^-7 \n', '\n',
      SVM_Drch_200_rbf_g100_t7_valid_ConfMat)
HM_valid_SVM_Drch_200_rbf_g100_t7_valid = sns.heatmap(SVM_Drch_200_rbf_g100_t7_valid_ConfMat, annot=False,
                                                      cmap='coolwarm', linecolor='black', linewidth=2)
plt.title('SVM-Ker=rbf gam=100 tol=10^-7/LDA 200 topics')
plt.savefig('HM_valid_SVM_Drch_200_rbf_g100_t7.png', dpi=600)

# Classification reports
SVM_Drch_200_rbf_g100_t7_valid_report = classification_report(SVM_Drch_200_rbf_g100_t7_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_Drch_200_rbf_g100_t7_valid_report)

# Dirichlet 1000 topics / SVM - Kernel=linear tol=1 x 10^-4
SVM_Drch_1000_lin_t4_valid_ConfMat = confusion_matrix(SVM_Drch_1000_lin_t4_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet 1000 topics / SVM - Kernel=linear tol=1 x 10^-4 \n', '\n',
      SVM_Drch_1000_lin_t4_valid_ConfMat)
HM_valid_SVM_Drch_1000_lin_t4_valid = sns.heatmap(SVM_Drch_1000_lin_t4_valid_ConfMat, annot=False, cmap='coolwarm',
                                                  linecolor='black', linewidth=2)
plt.title('SVM-Ker=linear tol=10^-4/LDA 1000 topics')
plt.savefig('HM_valid_SVM_Drch_1000_lin_t4.png', dpi=600)

# Classification reports
SVM_Drch_1000_lin_t4_valid_report = classification_report(SVM_Drch_1000_lin_t4_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_Drch_1000_lin_t4_valid_report)

"""#### ** Test"""

# Dirichlet 50 topics / SVM - Kernel=linear tol=1 x 10^-4
SVM_Drch_50_lin_t4_test_ConfMat = confusion_matrix(SVM_Drch_50_lin_t4_test, Test_Data_Y)
print('Confusion matrix : Dirichlet 50 topics / SVM - Kernel=linear tol=1 x 10^-4 \n', '\n',
      SVM_Drch_50_lin_t4_test_ConfMat)
HM_test_SVM_Drch_50_lin_t4_test = sns.heatmap(SVM_Drch_50_lin_t4_test_ConfMat, annot=False, cmap='coolwarm',
                                              linecolor='black', linewidth=2)
plt.title('SVM-Ker=linear tol=10^-4 /LDA 50 topics')
plt.savefig('HM_test_SVM_Drch_50_lin_t4.png', dpi=600)

# Classification reports
SVM_Drch_50_lin_t4_test_report = classification_report(SVM_Drch_50_lin_t4_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_Drch_50_lin_t4_test_report)

# Dirichlet 200 topics / SVM - Kernel=rbf gamma=100 tol=1 x 10^-7
SVM_Drch_200_rbf_g100_t7_test_ConfMat = confusion_matrix(SVM_Drch_200_rbf_g100_t7_test, Test_Data_Y)
print('Confusion matrix : Dirichlet 200 topics / SVM -Kernel=rbf gamma=100 tol=1 x 10^-7\n', '\n',
      SVM_Drch_200_rbf_g100_t7_test_ConfMat)
HM_test_SVM_Drch_200_rbf_g100_t7_test = sns.heatmap(SVM_Drch_200_rbf_g100_t7_test_ConfMat, annot=False, cmap='coolwarm',
                                                    linecolor='black', linewidth=2)
plt.title('SVM-Ker=rbf gam=100 tol=10^-7/LDA 200 topics')
plt.savefig('HM_test_SVM_Drch_200_rbf_g100_t7.png', dpi=600)

# Classification reports
SVM_Drch_200_rbf_g100_t7_test_report = classification_report(SVM_Drch_200_rbf_g100_t7_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_Drch_200_rbf_g100_t7_test_report)

# Dirichlet 1000 topics / SVM - Kernel=linear tol=1 x 10^-4
SVM_Drch_1000_lin_t4_test_ConfMat = confusion_matrix(SVM_Drch_1000_lin_t4_test, Test_Data_Y)
print('Confusion matrix : Dirichlet 1000 topics / SVM -Kernel=linear tol=1 x 10^-4\n', '\n',
      SVM_Drch_1000_lin_t4_test_ConfMat)
HM_test_SVM_Drch_1000_lin_t4_test = sns.heatmap(SVM_Drch_1000_lin_t4_test_ConfMat, annot=False, cmap='coolwarm',
                                                linecolor='black', linewidth=2)
plt.title('SVM-Ker=linear tol=10^-4/LDA 1000 topics')
plt.savefig('HM_test_SVM_Drch_1000_lin_t4.png', dpi=600)

# Classification reports
SVM_Drch_1000_lin_t4_test_report = classification_report(SVM_Drch_1000_lin_t4_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', SVM_Drch_1000_lin_t4_test_report)

"""### c-4-1) Creating pipelines : Train Neural Networks / BoW features - fit the models"""

# to train : BoW features / Neural Networks (MLP)

from sklearn.pipeline import Pipeline
from sklearn.neural_network import MLPClassifier

### MLP : hidden layer = (10,10) - LR = 1 x 10^-4
Pipe_10_BoW_NN_10104 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('4_MLP', MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(10, 10), random_state=1))
])

### MLP : hidden layer = (20,50) - LR = 1 x 10^-3
Pipe_10_BoW_NN_20503 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('4_MLP', MLPClassifier(solver='lbfgs', alpha=1e-3, hidden_layer_sizes=(20, 50), random_state=1))
])

# Fit the models - BoW / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
start_time = time.time()
Pipe_10_BoW_NN_10104.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - BoW / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
Pipe_10_BoW_NN_20503.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-4-1) To validate the BoW / Neural Networks models by validation set"""

# Predict the models by validation set - BoW / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
start_time = time.time()
NNs_BoW_10104_valid = Pipe_10_BoW_NN_10104.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - BoW / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
NNs_BoW_20503_valid = Pipe_10_BoW_NN_20503.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-4-1) To report the BoW / Neural Networks models by test set"""

# Predict the models by test set - BoW / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
start_time = time.time()
NNs_BoW_10104_test = Pipe_10_BoW_NN_10104.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - BoW / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
NNs_BoW_20503_test = Pipe_10_BoW_NN_20503.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-4-1) Performances : confusion matrix - BoW / NNs

#### ** Validation
"""

# BoW / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
NN_BoW_10104_valid_ConfMat = confusion_matrix(NNs_BoW_10104_valid, Valid_Data_Y)
print('Confusion matrix : BoW / NNs - hidden layer = (10,10) - LR = 1 x 10^-4 \n', '\n', NN_BoW_10104_valid_ConfMat)
HM_valid_NN_BoW_10104_valid = sns.heatmap(NN_BoW_10104_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('NNs-hidden layer=(10,10)-LR =10^-4/BoW')
plt.savefig('HM_valid_NN_BoW_10104.png', dpi=600)

# Classification reports
NN_BoW_10104_valid_report = classification_report(NNs_BoW_10104_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NN_BoW_10104_valid_report)

# BoW / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
NN_BoW_20503_valid_ConfMat = confusion_matrix(NNs_BoW_20503_valid, Valid_Data_Y)
print('Confusion matrix : BoW / NNs - hidden layer = (20,50) - LR = 1 x 10^-3 \n', '\n', NN_BoW_20503_valid_ConfMat)
HM_valid_NN_BoW_20503_valid = sns.heatmap(NN_BoW_20503_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('NNs-hidden layer=(20,50)-LR=10^-3/BoW')
plt.savefig('HM_valid_NN_BoW_20503.png', dpi=600)

# Classification reports
NN_BoW_20503_valid_report = classification_report(NNs_BoW_20503_valid, Valid_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NN_BoW_20503_valid_report)

"""#### ** Test"""

# BoW / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
NN_BoW_10104_test_ConfMat = confusion_matrix(NNs_BoW_10104_test, Test_Data_Y)
print('Confusion matrix : BoW / NNs - hidden layer = (10,10) - LR = 1 x 10^-4 \n', '\n', NN_BoW_10104_test_ConfMat)
HM_test_NN_BoW_10104_test = sns.heatmap(NN_BoW_10104_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                        linewidth=2)
plt.title('NNs-hidden layer=(10,10)-LR=10^-4/BoW')
plt.savefig('HM_test_NN_BoW_10104.png', dpi=600)

# Classification reports
NN_BoW_10104_test_report = classification_report(NNs_BoW_10104_test, Test_Data_Y)
print('Classification report : BoW / Naive Bayes \n', '\n', NN_BoW_10104_test_report)

# BoW / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
NN_BoW_20503_test_ConfMat = confusion_matrix(NNs_BoW_20503_test, Test_Data_Y)
print('Confusion matrix : BoW / NNs - hidden layer = (20,50) - LR = 1 x 10^-3 \n', '\n', NN_BoW_20503_test_ConfMat)
HM_test_NN_BoW_20503_test = sns.heatmap(NN_BoW_20503_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                        linewidth=2)
plt.title('NNs-hidden layer=(20,50)-LR=10^-3/BoW')
plt.savefig('HM_test_NN_BoW_20503.png', dpi=600)

# Classification reports
NN_BoW_20503_test_report = classification_report(NNs_BoW_20503_test, Test_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NN_BoW_20503_test_report)

"""### c-4-2) Creating pipelines : Train Neural Networks / TFIDF features - fit the models"""

# to train : TFIDF features / Neural Networks (MLP)

### MLP : hidden layer = (10,10) - LR = 1 x 10^-4
Pipe_11_TFIDF_NN_10104 = Pipeline([
    ('2_TFIDF_fit', TfidfVectorizer(analyzer=tokenization)),
    ('2_TFIDF_SpMat', TfidfTransformer()),
    ('4_MLP', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 10), random_state=1))
])

### MLP : hidden layer = (20,50) - LR = 1 x 10^-3
Pipe_11_TFIDF_NN_20503 = Pipeline([
    ('2_TFIDF_fit', TfidfVectorizer(analyzer=tokenization)),
    ('2_TFIDF_SpMat', TfidfTransformer()),
    ('4_MLP', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 50), random_state=1))
])

# Fit the models - TFIDF / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
start_time = time.time()
Pipe_11_TFIDF_NN_10104.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - TFIDF / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
Pipe_11_TFIDF_NN_20503.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-4-2) To validate the TFIDF / Neural Networks models by validation set"""

# Predict the models by validation set - TFIDF / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
start_time = time.time()
NNs_TFIDF_10104_valid = Pipe_11_TFIDF_NN_10104.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - TFIDF / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
NNs_TFIDF_20503_valid = Pipe_11_TFIDF_NN_20503.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-4-2) To report the TFIDF / Neural Networks models by test set"""

# Predict the models by test set - TFIDF / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
start_time = time.time()
NNs_TFIDF_10104_test = Pipe_11_TFIDF_NN_10104.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - TFIDF / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
NNs_TFIDF_20503_test = Pipe_11_TFIDF_NN_20503.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-4-2) Performances : confusion matrix - TFIDF / NNs

#### ** Validation
"""

# TFIDF / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
NN_TFIDF_10104_valid_ConfMat = confusion_matrix(NNs_TFIDF_10104_valid, Valid_Data_Y)
print('Confusion matrix : TFIDF / NNs - hidden layer = (10,10) - LR = 1 x 10^-4 \n', '\n', NN_TFIDF_10104_valid_ConfMat)
HM_valid_NN_TFIDF_10104_valid = sns.heatmap(NN_TFIDF_10104_valid_ConfMat, annot=False, cmap='coolwarm',
                                            linecolor='black', linewidth=2)
plt.title('NNs-hidden layer=(10,10)-LR=10^-4/TFIDF')
plt.savefig('HM_valid_NN_TFIDF_10104.png', dpi=600)

# Classification reports
NN_TFIDF_10104_valid_report = classification_report(NNs_TFIDF_10104_valid, Valid_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NN_TFIDF_10104_valid_report)

# TFIDF / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
NN_TFIDF_20503_valid_ConfMat = confusion_matrix(NNs_TFIDF_10104_valid, Valid_Data_Y)
print('Confusion matrix : TFIDF / NNs - hidden layer = (20,50) - LR = 1 x 10^-3 \n', '\n', NN_TFIDF_10104_valid_ConfMat)
HM_valid_NN_TFIDF_10104_valid = sns.heatmap(NN_TFIDF_20503_valid_ConfMat, annot=False, cmap='coolwarm',
                                            linecolor='black', linewidth=2)
plt.title('NNs-hidden layer=(20,50)-LR=10^-3/TFIDF')
plt.savefig('HM_valid_NN_TFIDF_10104.png', dpi=600)

# Classification reports
NNs_TFIDF_20503_valid_report = classification_report(NNs_TFIDF_20503_valid, Valid_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NNs_TFIDF_20503_valid_report)

"""#### ** Test"""

# TFIDF / NNs - hidden layer = (10,10) - LR = 1 x 10^-4
NN_TFIDF_10104_test_ConfMat = confusion_matrix(NNs_TFIDF_10104_test, Test_Data_Y)
print('Confusion matrix : TFIDF / NNs - hidden layer = (10,10) - LR = 1 x 10^-4 \n', '\n', NN_TFIDF_10104_test_ConfMat)
HM_test_NN_TFIDF_10104_test = sns.heatmap(NN_TFIDF_10104_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('NNs-hidden layer=(10,10)-LR=10^-4/TFIDF')
plt.savefig('HM_test_NN_TFIDF_10104.png', dpi=600)

# Classification reports
NNs_TFIDF_10104_test_report = classification_report(NNs_TFIDF_10104_test, Test_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NNs_TFIDF_10104_test_report)

# TFIDF / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
NN_TFIDF_20503_test_ConfMat = confusion_matrix(NNs_TFIDF_20503_test, Test_Data_Y)
print('Confusion matrix : TFIDF / NNs - hidden layer = (20,50) - LR = 1 x 10^-3 \n', '\n', NN_TFIDF_20503_test_ConfMat)
HM_test_NN_TFIDF_20503_test = sns.heatmap(NN_TFIDF_20503_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('NNs-hidden layer=(20,50)-LR=10^-3/TFIDF')
plt.savefig('HM_test_NN_TFIDF_20503.png', dpi=600)

# Classification reports
NNs_TFIDF_20503_test_report = classification_report(NNs_TFIDF_20503_test, Test_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NNs_TFIDF_20503_test_report)

"""### c-4-3) Creating pipelines : Train Neural Networks / Dirichlet features - fit the models"""

# to train : Dirichlet features / Neural Networks (MLP)

### Dirichlet 50 topics / MLP : hidden layer = (10,5) - LR = 1 x 10^-6
Pipe_12_Drch_NN_1056 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat',
     LatentDirichletAllocation(n_components=50, max_iter=15, learning_method='online', learning_offset=50.,
                               random_state=0)),
    ('4_MLP', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1))
])

### Dirichlet 500 topics / MLP : hidden layer = (20,50) - LR = 1 x 10^-3
Pipe_12_Drch_NN_20503 = Pipeline([
    ('1_BoW_fit', CountVectorizer(analyzer=tokenization)),
    ('3_Drchl_SpMat',
     LatentDirichletAllocation(n_components=500, max_iter=5, learning_method='online', learning_offset=50.,
                               random_state=0)),
    ('4_MLP', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 50), random_state=1))
])

# Fit the models - Dirichlet 200 topics / NNs - hidden layer = (10,5) - LR = 1 x 10^-6
start_time = time.time()
Pipe_12_Drch_NN_1056.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

# Fit the models - Dirichlet 1000 topics / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
Pipe_12_Drch_NN_20503.fit(Train_Data_X, Train_Data_Y)
end_time = time.time()
print('Calculation time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### d-4-3) To validate the Dirichlet / Neural Networks models by validation set"""

# Predict the models by validation set - Dirichlet 200 topics / NNs - hidden layer = (10,5) - LR = 1 x 10^-6
start_time = time.time()
NNs_Drch_1056_valid = Pipe_12_Drch_NN_1056.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by validation set - Dirichlet 1000 topics / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
NNs_Drch_20503_valid = Pipe_12_Drch_NN_20503.predict(Valid_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### e-4-3) To report the Dirichlet /  Neural Networks models by test set"""

# Predict the models by test set - Dirichlet 200 topics / NNs - hidden layer = (10,5) - LR = 1 x 10^-6
start_time = time.time()
NNs_Drch_1056_test = Pipe_12_Drch_NN_1056.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

# Predict the models by test set - Dirichlet 1000 topics / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
start_time = time.time()
NNs_Drch_20503_test = Pipe_12_Drch_NN_20503.predict(Test_Data_X)
end_time = time.time()
print('\n Prediction time : %0.1f minutes' % ((end_time - start_time) / 60))

"""### f-4-3) Performances : confusion matrix - Dirichlet / NNs

#### ** Validation
"""

# Dirichlet 200 topics / NNs - hidden layer = (10,5) - LR = 1 x 10^-6
NN_Drch_1056_valid_ConfMat = confusion_matrix(NNs_Drch_1056_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet 50 / NNs - hidden layer = (10,5) - LR = 1 x 10^-6 \n', '\n',
      NN_Drch_1056_valid_ConfMat)
HM_valid_NN_Drch_1056_valid = sns.heatmap(NN_Drch_1056_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                          linewidth=2)
plt.title('NNs-hidden layer=(10,5)-LR=10^-6/LDA 200')
plt.savefig('HM_valid_NN_Drch_1056.png', dpi=600)

# Classification reports
NNs_Drch_1056_valid_report = classification_report(NNs_Drch_1056_valid, Valid_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NNs_Drch_1056_valid_report)

# Dirichlet 500 topics / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
NN_Drch_20503_valid_ConfMat = confusion_matrix(NNs_Drch_20503_valid, Valid_Data_Y)
print('Confusion matrix : Dirichlet 500 / NNs - hidden layer = (20,50) - LR = 1 x 10^-3 \n', '\n',
      NN_Drch_20503_valid_ConfMat)
HM_valid_NN_Drch_20503_valid = sns.heatmap(NN_Drch_20503_valid_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                           linewidth=2)
plt.title('NNs-hidden layer=(20,50)-LR=10^-3/LDA 500')
plt.savefig('HM_valid_NN_Drch_20503.png', dpi=600)

# Classification reports
NNs_Drch_20503_valid_report = classification_report(NNs_Drch_20503_valid, Valid_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NNs_Drch_20503_valid_report)

"""#### ** Test"""

# Dirichlet 200 topics / NNs - hidden layer = (10,5) - LR = 1 x 10^-6
NN_Drch_1056_test_ConfMat = confusion_matrix(NNs_Drch_1056_test, Test_Data_Y)
print('Confusion matrix : Dirichlet 50 / NNs - hidden layer = (10,5) - LR = 1 x 10^-6 \n', '\n',
      NN_Drch_1056_test_ConfMat)
HM_test_NN_Drch_1056_test = sns.heatmap(NN_Drch_1056_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                        linewidth=2)
plt.title('NNs-hidden layer=(10,5)-LR=10^-6/LDA 200')
plt.savefig('HM_test_NN_Drch_1056.png', dpi=600)

# Classification reports
NNs_Drch_526_test_report = classification_report(NNs_Drch_1056_test, Test_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NNs_Drch_526_test_report)

# Dirichlet 1000 topics / NNs - hidden layer = (20,50) - LR = 1 x 10^-3
NN_Drch_20503_test_ConfMat = confusion_matrix(NNs_Drch_20503_test, Test_Data_Y)
print('Confusion matrix : Dirichlet 50 / NNs - hidden layer = (20,50) - LR = 1 x 10^-3 \n', '\n',
      NN_Drch_20503_test_ConfMat)
HM_test_NN_Drch_20503_test = sns.heatmap(NN_Drch_20503_test_ConfMat, annot=False, cmap='coolwarm', linecolor='black',
                                         linewidth=2)
plt.title('NNs-hidden layer=(20,50)-LR=10^-3/LDA 500')
plt.savefig('HM_test_NN_Drch_20503.png', dpi=600)

# Classification reports
NNs_Drch_20503_test_report = classification_report(NNs_Drch_20503_test, Test_Data_Y)
print('Classification report : Dirichlet / Neural Networks \n', '\n', NNs_Drch_20503_test_report)
